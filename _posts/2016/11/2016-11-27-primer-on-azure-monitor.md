---
title:  Primer on Azure Monitor
date:  11/28/2016 00:00:01
permalink:  "/2016/11/27/primer-on-azure-monitor/"
categories:
- Solution
tags:
- Automation
- Data
- Security
- Virtual Machines
---
<a href="assets/2016/11/primer-on-azure-monitor/pexels-photo-423841.jpg"><img style="background-image:none;float:right;padding-top:0;padding-left:0;display:inline;padding-right:0;border-width:0;" title="pexels-photo-42384[1]" src="assets/2016/11/primer-on-azure-monitor/pexels-photo-423841_thumb.jpg" alt="pexels-photo-42384[1]" width="640" height="427" align="right" border="0" /></a>

<a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview" target="_blank">Azure Monitor</a> is the latest evolution of a set of technologies allowing Azure resources monitoring.

I’ve written about <a href="https://vincentlauzon.com/2015/09/06/analysing-application-logs-with-documentdb/">going the extra mile to be able to analyze logs</a> in the past.

The thing is that once our stuff is in production with tons of users hitting it, it might very well start behaving in unpredictable ways.  If we do not have a monitoring strategy, we’re going to be blind to problems and only see unrelated symptoms.

Azure Monitor is a great set of tools.  It doesn’t try to be the end all solution.  On the contrary, although it offers analytics out of the box, it let us export the logs wherever we want to go further.

I found the documentation of Azure Monitor (as of November 2016) a tad confusing, so I thought I would give a summary overview here.  Hopefully it will get you started.
<h2>Three types of sources</h2>
First thing we come across in Azure Monitor’s literature is the three types of sources:  Activity Logs, Diagnostic Logs &amp; Metrics.

There is a bit of confusion between Diagnostic Logs &amp; Metrics, some references hinting towards the fact that metrics are generated by Azure while diagnostics are generated by the resource itself.  That is confusing &amp; beside the point.  Let’s review those sources here.

<a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-activity-logs">Activity logs</a> capture all operations performed on Azure resources.  They used to be called Audit Logs &amp; Operational Logs.  Those comes directly from Azure APIs.  Any operations done on an Azure API (except HTTP-GET operations) traces an activity log.  Activity log are in JSON and contain the following information:  action, caller, status &amp; time stamp.  We’ll want to keep track of those to understand changes done in our Azure environments.

<a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-metrics">Metrics</a> are emitted by most Azure resources.  They are akin to performance counter, something that has a value (e.g. % CPU, IOPS, # messages in a queue, etc.) over time ; hence Azure Monitor, in the portal, allows us to plot those against time.  Metrics typically comes in JSON and tend to be emitted at regular interval (e.g. every minute) ; see <a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-supported-metrics" target="_blank">this articles</a> for available metrics.  We’ll want to check those to make sure our resources operate within expected bounds.

<a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-of-diagnostic-logs">Diagnostic logs</a> are logs emitted by a resource that provide detailed data about the operation of that particular resource.  That one is specific to the resource in terms of content:  each resource will have different logs.  Format will also vary (e.g. JSON, CSV, etc.), <a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-overview-of-diagnostic-logs#supported-services-and-schema-for-diagnostic-logs" target="_blank">see this article for different schemas</a>.  They also tend to be much more voluminous for an active resource.

That’s it.  That’s all there is to it.  Avoid the confusion and re-read the last three paragraphs.  It’s a time saver.  Promised.

We’ll discuss the export mechanisms &amp; alerts below, but for now, here’s a summary of the capacity (as of November 2016) of each source:
<table border="3" width="817">
<thead>
<tr style="background:green;color:white;">
<th>Source</th>
<th>Export to</th>
<th>Supports Alerts</th>
</tr>
</thead>
<tbody>
<tr>
<td>Activity Logs</td>
<td>Storage Account &amp; Event Hub</td>
<td>Yes</td>
</tr>
<tr>
<td>Metrics</td>
<td>Storage Account, Event Hub &amp; Log Analytics</td>
<td>Yes</td>
</tr>
<tr>
<td>Diagnostics Logs</td>
<td>Storage Account, Event Hub &amp; Log Analytics</td>
<td>No</td>
</tr>
</tbody>
</table>
<h3>Activity Log example</h3>
We can see the activity log of our favorite subscription by opening the monitor blade, which should be on the left hand side, in the <a href="https://portal.azure.com">https://portal.azure.com</a>.

<a href="assets/2016/11/primer-on-azure-monitor/image.png"><img style="background-image:none;padding-top:0;padding-left:0;display:inline;padding-right:0;border-width:0;" title="image" src="assets/2016/11/primer-on-azure-monitor/image_thumb.png" alt="image" width="176" height="480" border="0" /></a>

If you do not find it there, hit the <em>More Services</em> and search for <em>Monitor</em>.

Selecting the <em>Activity Logs, </em>we should have a search form and some results.

<a href="assets/2016/11/primer-on-azure-monitor/image1.png"><img style="background-image:none;padding-top:0;padding-left:0;display:inline;padding-right:0;border-width:0;" title="image" src="assets/2016/11/primer-on-azure-monitor/image_thumb1.png" alt="image" width="640" height="261" border="0" /></a>

<em>ListKeys</em> is a popular one.  Despite being conceptually a read operation, the List Key action, on a storage account, is done through a POST in the Azure REST API, specifically to trigger an audit trail.

We can select one of those <em>ListKeys</em> and, in the tray below, select the JSON format:

[code language="javascript"]

{
&quot;relatedEvents&quot;: [],
&quot;authorization&quot;: {
&quot;action&quot;: &quot;Microsoft.Storage/storageAccounts/listKeys/action&quot;,
&quot;condition&quot;: null,
&quot;role&quot;: null,
&quot;scope&quot;: &quot;/subscriptions/&lt;MY SUB GUID&gt;/resourceGroups/securitydata/providers/Microsoft.Storage/storageAccounts/a92430canadaeast&quot;
},
&quot;caller&quot;: null,
&quot;category&quot;: {
&quot;localizedValue&quot;: &quot;Administrative&quot;,
&quot;value&quot;: &quot;Administrative&quot;
},
&quot;claims&quot;: {},
&quot;correlationId&quot;: &quot;6c619af4-453e-4b24-8a4c-508af47f2b26&quot;,
&quot;description&quot;: &quot;&quot;,
&quot;eventChannels&quot;: 2,
&quot;eventDataId&quot;: &quot;09d35196-1cae-4eca-903d-6e9b1fc71a78&quot;,
&quot;eventName&quot;: {
&quot;localizedValue&quot;: &quot;End request&quot;,
&quot;value&quot;: &quot;EndRequest&quot;
},
&quot;eventTimestamp&quot;: &quot;2016-11-26T21:07:41.5355248Z&quot;,
&quot;httpRequest&quot;: {
&quot;clientIpAddress&quot;: &quot;104.208.33.166&quot;,
&quot;clientRequestId&quot;: &quot;ba51469e-9339-4329-b957-de5d3071d719&quot;,
&quot;method&quot;: &quot;POST&quot;,
&quot;uri&quot;: null
},

[/code]

I truncated the JSON here.  Basically, it is an activity event with all the details.
<h3>Metrics example</h3>
Metrics can be accessed from the “global” Monitor blade or from any Azure resource’s monitor blade.

Here I look at the CPU usage of an Azure Data Warehouse resource (which hasn’t run for months, hence flat lining).

<a href="assets/2016/11/primer-on-azure-monitor/image2.png"><img style="background-image:none;padding-top:0;padding-left:0;display:inline;padding-right:0;border-width:0;" title="image" src="assets/2016/11/primer-on-azure-monitor/image_thumb2.png" alt="image" width="640" height="292" border="0" /></a>
<h3>Diagnostic Logs example</h3>
For diagnostics, let’s create a storage account and activate diagnostics on it.  For this, under the <em>Monitoring </em>section, let’s select <em>Diagnostics</em>, make sure the status is <em>On</em> and then select <em>Blob logs</em>.

<a href="assets/2016/11/primer-on-azure-monitor/image3.png"><img style="background-image:none;padding-top:0;padding-left:0;display:inline;padding-right:0;border-width:0;" title="image" src="assets/2016/11/primer-on-azure-monitor/image_thumb3.png" alt="image" width="422" height="480" border="0" /></a>

We’ll notice that all metrics were already selected.  We also noticed that the retention is controlled there, in this case 7 days.

Let’s create a blob container, copy a file into it and try to access it via its URL.  Then let’s wait a few minutes for the diagnostics to be published.

We should see a special <em>$logs</em> container in the storage account.  This container will contain log files, stored by date &amp; time.  For instance for the first file, just taking the first couple of lines:

[code language="text"]

1.0;2016-11-26T20:48:00.5433672Z;&lt;strong&gt;GetContainerACL&lt;/strong&gt;;Success;200;3;3;authenticated;monitorvpl;monitorvpl;blob;&quot;https://monitorvpl.blob.core.windows.net:443/$logs?restype=container&amp;amp;comp=acl&quot;;&quot;/monitorvpl/$logs&quot;;295a75a6-0001-0021-7b26-48c117000000;0;184.161.153.48:51484;2015-12-11;537;0;217;62;0;;;&quot;&amp;quot;0x8D4163D73154695&amp;quot;&quot;;Saturday, 26-Nov-16 20:47:34 GMT;;&quot;Microsoft Azure Storage Explorer, 0.8.5, win32, Azure-Storage/1.2.0 (NODE-VERSION v4.1.1; Windows_NT 10.0.14393)&quot;;;&quot;9e78fc90-b419-11e6-a392-8b41713d952c&quot;
1.0;2016-11-26T20:48:01.0383516Z;&lt;strong&gt;GetContainerACL&lt;/strong&gt;;Success;200;3;3;authenticated;monitorvpl;monitorvpl;blob;&quot;https://monitorvpl.blob.core.windows.net:443/$logs?restype=container&amp;amp;comp=acl&quot;;&quot;/monitorvpl/$logs&quot;;06be52d9-0001-0093-7426-483a6d000000;0;184.161.153.48:51488;2015-12-11;537;0;217;62;0;;;&quot;&amp;quot;0x8D4163D73154695&amp;quot;&quot;;Saturday, 26-Nov-16 20:47:34 GMT;;&quot;Microsoft Azure Storage Explorer, 0.8.5, win32, Azure-Storage/1.2.0 (NODE-VERSION v4.1.1; Windows_NT 10.0.14393)&quot;;;&quot;9e9c6311-b419-11e6-a392-8b41713d952c&quot;
1.0;2016-11-26T20:48:33.4973667Z;&lt;strong&gt;PutBlob&lt;/strong&gt;;Success;201;6;6;authenticated;monitorvpl;monitorvpl;blob;&quot;https://monitorvpl.blob.core.windows.net:443/sample/A.txt&quot;;&quot;/monitorvpl/sample/A.txt&quot;;965cb819-0001-0000-2a26-48ac26000000;0;184.161.153.48:51622;2015-12-11;655;7;258;0;7;&quot;Tj4nPz2/Vt7I1KEM2G8o4A==&quot;;&quot;Tj4nPz2/Vt7I1KEM2G8o4A==&quot;;&quot;&amp;quot;0x8D4163D961A76BE&amp;quot;&quot;;Saturday, 26-Nov-16 20:48:33 GMT;;&quot;Microsoft Azure Storage Explorer, 0.8.5, win32, Azure-Storage/1.2.0 (NODE-VERSION v4.1.1; Windows_NT 10.0.14393)&quot;;;&quot;b2006050-b419-11e6-a392-8b41713d952c&quot;

[/code]

Storage Account diagnostics obviously log in semicolon delimited values (variant of CSV), which isn’t trivial to read the way I pasted it here.  But basically we can see the logs contain details:  each operation done around the blobs are logged with lots of details.
<h2>Querying</h2>
As seen in the examples, Azure Monitor allows us to query the logs.  This can be done in the portal but also using Azure Monitor REST API, cross platform Command-Line Interface (CLI) commands, PowerShell cmdlets or the .NET SDK.
<h2>Export</h2>
We can export the sources to a Storage Account and specify a retention period in days.  We can also export them to Azure Event Hubs &amp; Azure Log Analytics.  As specified in the table above, <u>Activity logs can’t be sent to Log Analytics</u>.  Also, Activity logs <a href="https://powerbi.microsoft.com/en-us/documentation/powerbi-content-pack-azure-audit-logs/" target="_blank">can be analyzed using Power BI</a>.

There are a few reasons why we would export the logs:
<ul>
 	<li>Archiving scenario:  Azure Monitor keeps content for 30 days.  If we need more retention, we need to archive it ourselves.  We can do that by exporting the content to a storage account ; this also enables big data scenario where we keep the logs for future data mining.</li>
 	<li>Analytics:  Log Analytics offers more capacity for analyzing content.  It also offers 30 days of retention by default but can be extended to one year.  Basically, this would <em>upgrade</em> us to Log Analytics.</li>
</ul>
<ul>
 	<li>Alternatively, we could export the logs to a storage account where they could be ingested by another SIEM (e.g. HP Arcsight).  See <a href="https://azsiempublicdrops.blob.core.windows.net/drops/Azure%20SIEM%20Integrator%20User%20Guide.pdf" target="_blank">this article</a> for details about SIEM integration.</li>
 	<li>Near real time analysis:  Azure Event Hubs allow us to send the content to many different places, but also we could analyze it <em>on the fly</em> using <a href="https://docs.microsoft.com/en-us/azure/stream-analytics/" target="_blank">Azure Stream Analytics</a>.</li>
</ul>
<h2>Alerts (Notifications)</h2>
Both Activity Logs &amp; Metrics can trigger alerts.  Currently (as of November 2016), only Metrics alert can be set in the portal ; Activity Logs alerts must be set by PowerShell, CLI or REST API.

Alerts are a powerful way to automatically react to our Azure resource behaviors ; when certain conditions are met (e.g. for a metric, when a value exceeds a threshold for a given period of time), the alert can send an email to a specified list of email addresses but also, it can invoke a Web Hook.

Again, the ability to invoke a web hook opens up the platform.  We could, for instance, expose an Azure Automation runbook as a Web Hook ; it therefore means an alert could trigger whatever a runbook is able to do.
<h2>Security</h2>
There are <a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-roles-permissions-security#built-in-monitoring-roles" target="_blank">two RBAC roles</a> around monitoring:  Reader &amp; Contributor.

There are also some <a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/monitoring-roles-permissions-security#security-considerations-for-monitoring-data" target="_blank">security considerations</a> around monitoring:
<ul>
 	<li>Use a dedicated storage account (or multiple dedicated storage accounts) for monitoring data.  Basically, avoid mixing monitoring and “other” data, so that people do not gain access to monitoring data inadvertently and, vis versa, that people needing access to monitoring data do not gain access to “other” data (e.g. sensitive business data).</li>
 	<li>For the same reasons, use a dedicated namespace with Event Hubs</li>
 	<li>Limit access to monitoring data by using RBAC, e.g. by putting them in a separate resource group</li>
 	<li>Never grant <em>ListKeys</em> permission across a subscription as users could then gain access to reading monitoring data</li>
 	<li>If you need to give access to monitoring data, consider using a SAS token (for either Storage Account or Event Hubs)</li>
</ul>
<h2>Summary</h2>
Azure Monitor brings together a suite of tools to monitor our Azure resources.  It is an open platform in the sense it integrates easily with solutions that can complement it.